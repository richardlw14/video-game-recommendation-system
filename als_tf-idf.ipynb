{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<threadpoolctl.threadpool_limits at 0x26da486acc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "from threadpoolctl import threadpool_limits\n",
    "threadpool_limits(1, \"blas\")  # Limits BLAS to a single thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_memory(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'float64':\n",
    "            df[col] = df[col].astype('float32')\n",
    "        if df[col].dtype == 'int64':\n",
    "            df[col] = df[col].astype('int32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "import json\n",
    "\n",
    "#Step 1: Read csv files\n",
    "#WIN\n",
    "games_df = reduce_memory(pd.read_csv(r'C:\\Users\\richa\\Documents\\UCI\\CS 271P\\games.csv'))\n",
    "rec_df = reduce_memory(pd.read_csv(r'C:\\Users\\richa\\Documents\\UCI\\CS 271P\\recommendations.csv'))\n",
    "with open(r'C:\\Users\\richa\\Documents\\UCI\\CS 271P\\games_metadata.json', encoding=\"utf-8\") as file:\n",
    "     metadata = [json.loads(line) for line in file]\n",
    "metadata_df = pd.DataFrame(metadata)\n",
    "\n",
    "games_df = games_df.head(10000)\n",
    "rec_df = rec_df[rec_df['app_id'].isin(games_df['app_id'])]\n",
    "\n",
    "games_df = games_df[games_df['app_id'].isin(rec_df['app_id'])] #to ensure all games exist in rec_df\n",
    "metadata_df = metadata_df[metadata_df['app_id'].isin(rec_df['app_id'])]\n",
    "\n",
    "#MACOS\n",
    "# games_df = pd.read_csv('/Users/richardlw/Documents/UCI/CS 271P/games-rec-system/test_dataset/games_df_test.csv')\n",
    "# rec_df = pd.read_csv('/Users/richardlw/Documents/UCI/CS 271P/games-rec-system/test_dataset/rec_df_test.csv')\n",
    "# metadata_df = pd.read_csv('/Users/richardlw/Documents/UCI/CS 271P/games-rec-system/test_dataset/metadata_df_test.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Step 2: Filter Active Users and Games\n",
    "# Keep users with >100 reviews\n",
    "user_activity = rec_df['user_id'].value_counts()\n",
    "\n",
    "filtered_users = user_activity[user_activity > 100].index\n",
    "\n",
    "filtered_rec_df = rec_df[\n",
    "    rec_df['user_id'].isin(filtered_users)\n",
    "]\n",
    "\n",
    "filtered_rec_df = filtered_rec_df.copy()\n",
    "filtered_rec_df['hours'] = np.log1p(filtered_rec_df['hours'])\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_fraction = 0.8\n",
    "train_df = filtered_rec_df.sample(frac=train_fraction, random_state=42)\n",
    "test_df = filtered_rec_df.drop(train_df.index)\n",
    "\n",
    "test_df = test_df[test_df['app_id'].isin(train_df['app_id'])]\n",
    "\n",
    "# Step 3: Create the User-Item Interaction Matrix\n",
    "# Use hours played as confidence scores\n",
    "interaction_sparse = csr_matrix(\n",
    "    (\n",
    "        train_df['hours'],  # Confidence score\n",
    "        (\n",
    "            train_df['user_id'].astype('category').cat.codes,\n",
    "            train_df['app_id'].astype('category').cat.codes\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create mappings for user and game IDs\n",
    "user_mapping = dict(enumerate(train_df['user_id'].astype('category').cat.categories))\n",
    "game_mapping = dict(enumerate(train_df['app_id'].astype('category').cat.categories))\n",
    "reverse_user_mapping = {v: k for k, v in user_mapping.items()}\n",
    "reverse_game_mapping = {v: k for k, v in game_mapping.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eabf64652841428f9a7b3a974098f517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 4: Train the ALS Model\n",
    "# Initialize ALS model with hyperparameters\n",
    "als_model = AlternatingLeastSquares(factors=100, regularization=0.05, iterations=20, use_gpu=False)\n",
    "\n",
    "# Fit the model to the interaction data\n",
    "als_model.fit(interaction_sparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Step 5: Compute Metadata Similarity\n",
    "# Convert tags and description to strings and combine\n",
    "#metadata_df = metadata_df[metadata_df['app_id'].isin(train_df['app_id'])]\n",
    "\n",
    "metadata_df['tags'] = metadata_df['tags'].fillna('')\n",
    "metadata_df['description'] = metadata_df['description'].fillna('')\n",
    "\n",
    "metadata_df['tags'] = metadata_df['tags'].apply(lambda x: ' '.join(x) if isinstance(x, list) else str(x))\n",
    "metadata_df['description'] = metadata_df['description'].fillna('').astype(str)\n",
    "metadata_df['combined_metadata'] = metadata_df['tags'] + ' ' + metadata_df['description']\n",
    "\n",
    "# Use TF-IDF to compute metadata similarities\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "tfidf_matrix = tfidf.fit_transform(metadata_df['combined_metadata'])\n",
    "\n",
    "# Compute cosine similarity between items\n",
    "metadata_similarity = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Normalize similarity matrix\n",
    "scaler = MinMaxScaler()\n",
    "metadata_similarity_normalized = scaler.fit_transform(metadata_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game recommendations for User 5136021:\n",
      "Two Worlds Epic Edition\n",
      "How to Survive 2\n",
      "Ninja Stealth\n",
      "Space Pilgrim Episode III: Delta Pavonis\n",
      "Razortron 2000\n",
      "BADLAND: Game of the Year Edition\n",
      "APB Reloaded\n",
      "Urban Trial Freestyle\n",
      "Shower With Your Dad Simulator 2015: Do You Still Shower With Your Dad\n",
      "Zombie Army Trilogy\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Create function for hybrid recommendation system\n",
    "def hybrid_recommendations(user_id, als_model, metadata_similarity, alpha=0.5, N=10):\n",
    "    # Check if user exists in training data\n",
    "    if user_id not in user_mapping.values():\n",
    "        return []\n",
    "\n",
    "    user_index = reverse_user_mapping[user_id]\n",
    "\n",
    "    # Generate ALS recommendations\n",
    "    recommended = als_model.recommend(\n",
    "        userid=user_id,\n",
    "        user_items=interaction_sparse[user_index],\n",
    "        N=N,\n",
    "        filter_already_liked_items=True,\n",
    "        recalculate_user=True\n",
    "    )\n",
    "\n",
    "    # Extract ALS recommendations and scores\n",
    "    als_recommendations = recommended[0]  # Indices of recommended items\n",
    "    als_scores = recommended[1]  # Corresponding ALS scores\n",
    "\n",
    "    # Compute metadata similarity scores for recommended items\n",
    "    hybrid_scores = []\n",
    "\n",
    "    for idx, als_item in enumerate(als_recommendations):\n",
    "        metadata_scores = metadata_similarity[als_item, als_recommendations]\n",
    "        hybrid_score = alpha * als_scores[idx] + (1 - alpha) * metadata_scores.mean()\n",
    "        hybrid_scores.append(hybrid_score)\n",
    "\n",
    "    # Combine and sort by hybrid score\n",
    "    hybrid_recommendations = [\n",
    "        game_mapping[item]\n",
    "        for item, _ in sorted(zip(als_recommendations, hybrid_scores), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Map app IDs to titles using games_df\n",
    "    app_titles = games_df.set_index('app_id').loc[hybrid_recommendations, 'title'].tolist()\n",
    "\n",
    "    return app_titles[:N]\n",
    "\n",
    "# Step 7: Generate Hybrid Recommendations for a Sample User\n",
    "sample_user_id = train_df['user_id'].iloc[0]  # Replace with actual user ID\n",
    "alpha = 0.6  # Weight for ALS\n",
    "N = 10  # Number of recommendations\n",
    "recommendations = hybrid_recommendations(sample_user_id, als_model, metadata_similarity_normalized, alpha, N)\n",
    "\n",
    "print(f\"Game recommendations for User {sample_user_id}:\\n\" + \"\\n\".join(recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Ratio (Hybrid): 0.7930\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate hit ratio for the hybrid recommendation system\n",
    "# Revised evaluation function\n",
    "def evaluate_hit_ratio_hybrid(test_df, N=10, alpha=0.6):\n",
    "    title_to_app_id = games_df.set_index('title')['app_id'].to_dict()\n",
    "\n",
    "    users_test = test_df['user_id'].unique()  # Unique users in the test set\n",
    "    hit_count = 0\n",
    "\n",
    "    for user_id in users_test:\n",
    "        # Generate hybrid recommendations using the hybrid_recommendations function\n",
    "        recommended_games = hybrid_recommendations(user_id, als_model, metadata_similarity_normalized, alpha, N)\n",
    "\n",
    "        recommended_games = [title_to_app_id[title] for title in recommended_games if title in title_to_app_id]\n",
    "\n",
    "        # Get the user's actual test interactions from test_df\n",
    "        user_test_games = test_df[test_df['user_id'] == user_id]['app_id'].values\n",
    "\n",
    "        # Check if any recommended game matches the user's test games\n",
    "        if any(game in user_test_games for game in recommended_games):\n",
    "            hit_count += 1\n",
    "\n",
    "    # Calculate Hit Ratio\n",
    "    hit_ratio = hit_count / len(users_test)\n",
    "    return hit_ratio\n",
    "\n",
    "\n",
    "# Evaluate Hit Ratio for the hybrid recommendation system\n",
    "hit_ratio_hybrid = evaluate_hit_ratio_hybrid(test_df, N=10, alpha=0.8)\n",
    "print(f\"Hit Ratio (Hybrid): {hit_ratio_hybrid:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
